<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7622aa72f9e676e593339f5f694ecd7d",
  "translation_date": "2025-05-20T09:20:49+00:00",
  "source_file": "05-agentic-rag/README.md",
  "language_code": "fa"
}
-->
[![Agentic RAG](../../../translated_images/lesson-5-thumbnail.1bab9551989766fa0dbea97c250a68c41e0f36ed9b02d3aa8ee8fdcc62596981.fa.png)](https://youtu.be/WcjAARvdL7I?si=BCgwjwFb2yCkEhR9)

> _(برای مشاهده ویدئوی این درس روی تصویر بالا کلیک کنید)_

# Agentic RAG

این درس مروری جامع بر Agentic Retrieval-Augmented Generation (Agentic RAG) ارائه می‌دهد، یک پارادایم نوظهور در هوش مصنوعی که در آن مدل‌های زبان بزرگ (LLMها) به‌صورت خودگردان برنامه‌ریزی می‌کنند که گام بعدی خود را بردارند و همزمان اطلاعات را از منابع خارجی استخراج کنند. برخلاف الگوهای ایستا که ابتدا بازیابی و سپس خواندن انجام می‌شود، Agentic RAG شامل فراخوانی‌های تکراری به LLM است که در میان آن‌ها فراخوانی ابزار یا توابع و خروجی‌های ساختاریافته قرار دارد. سیستم نتایج را ارزیابی می‌کند، پرسش‌ها را اصلاح می‌کند، در صورت نیاز ابزارهای بیشتری را فراخوانی می‌کند و این چرخه را تا رسیدن به راه‌حل رضایت‌بخش ادامه می‌دهد.

## مقدمه

این درس موارد زیر را پوشش می‌دهد:

- **درک Agentic RAG:** آشنایی با پارادایم نوظهور در هوش مصنوعی که در آن مدل‌های زبان بزرگ (LLMها) به‌صورت خودگردان برنامه‌ریزی می‌کنند که گام بعدی خود را بردارند و همزمان اطلاعات را از منابع داده خارجی استخراج کنند.
- **درک سبک تکراری Maker-Checker:** فهم چرخه فراخوانی‌های تکراری به LLM که در میان آن‌ها فراخوانی ابزار یا تابع و خروجی‌های ساختاریافته قرار دارد، که برای بهبود دقت و مدیریت پرسش‌های نادرست طراحی شده است.
- **بررسی کاربردهای عملی:** شناسایی موقعیت‌هایی که Agentic RAG در آن‌ها برتری دارد، مانند محیط‌های اولویت‌دار بر صحت، تعاملات پیچیده با پایگاه‌های داده و جریان‌های کاری گسترده.

## اهداف یادگیری

پس از اتمام این درس، شما قادر خواهید بود:

- **درک Agentic RAG:** با پارادایم نوظهور در هوش مصنوعی آشنا شوید که مدل‌های زبان بزرگ (LLMها) به‌صورت خودگردان برنامه‌ریزی می‌کنند که گام بعدی خود را بردارند و همزمان اطلاعات را از منابع داده خارجی استخراج کنند.
- **سبک تکراری Maker-Checker:** مفهوم چرخه فراخوانی‌های تکراری به LLM که در میان آن‌ها فراخوانی ابزار یا تابع و خروجی‌های ساختاریافته قرار دارد را درک کنید، که برای بهبود دقت و مدیریت پرسش‌های نادرست طراحی شده است.
- **مالکیت فرایند استدلال:** توانایی سیستم برای مالکیت فرایند استدلال خود، اتخاذ تصمیم درباره نحوه حل مسائل بدون اتکا به مسیرهای از پیش تعریف شده را درک کنید.
- **جریان کاری:** بفهمید چگونه یک مدل عامل به‌طور مستقل تصمیم می‌گیرد گزارش‌های روند بازار را بازیابی کند، داده‌های رقبا را شناسایی کند، شاخص‌های فروش داخلی را همبسته کند، یافته‌ها را ترکیب کند و استراتژی را ارزیابی نماید.
- **حلقه‌های تکراری، ادغام ابزار و حافظه:** درباره تکیه سیستم بر الگوی تعامل حلقه‌ای، حفظ حالت و حافظه در طول مراحل برای جلوگیری از تکرارهای بی‌مورد و اتخاذ تصمیمات آگاهانه بیاموزید.
- **مدیریت خطاها و خوداصلاحی:** با مکانیزم‌های قوی خوداصلاحی سیستم، از جمله تکرار و بازپرسش، استفاده از ابزارهای تشخیصی و اتکا به نظارت انسانی آشنا شوید.
- **محدودیت‌های عامل بودن:** محدودیت‌های Agentic RAG را در حوزه خودمختاری تخصصی، وابستگی به زیرساخت و احترام به محدودیت‌ها درک کنید.
- **موارد استفاده عملی و ارزش:** موقعیت‌هایی که Agentic RAG در آن‌ها عملکرد خوبی دارد، مانند محیط‌های اولویت‌دار بر صحت، تعاملات پیچیده با پایگاه‌های داده و جریان‌های کاری گسترده را شناسایی کنید.
- **حاکمیت، شفافیت و اعتماد:** اهمیت حاکمیت و شفافیت، از جمله استدلال قابل توضیح، کنترل تعصب و نظارت انسانی را بیاموزید.

## Agentic RAG چیست؟

Agentic Retrieval-Augmented Generation (Agentic RAG) پارادایم نوظهوری در هوش مصنوعی است که در آن مدل‌های زبان بزرگ (LLMها) به‌صورت خودگردان برنامه‌ریزی می‌کنند که گام بعدی خود را بردارند و همزمان اطلاعات را از منابع خارجی استخراج کنند. برخلاف الگوهای ایستا که ابتدا بازیابی و سپس خواندن انجام می‌شود، Agentic RAG شامل فراخوانی‌های تکراری به LLM است که در میان آن‌ها فراخوانی ابزار یا توابع و خروجی‌های ساختاریافته قرار دارد. سیستم نتایج را ارزیابی می‌کند، پرسش‌ها را اصلاح می‌کند، در صورت نیاز ابزارهای بیشتری را فراخوانی می‌کند و این چرخه را تا رسیدن به راه‌حل رضایت‌بخش ادامه می‌دهد. این سبک تکراری «سازنده-بازرس» دقت را بهبود می‌بخشد، پرسش‌های نادرست را مدیریت می‌کند و نتایج با کیفیت بالا را تضمین می‌کند.

سیستم به‌طور فعال مالک فرایند استدلال خود است، پرسش‌های ناموفق را بازنویسی می‌کند، روش‌های بازیابی متفاوتی را انتخاب می‌کند و ابزارهای متعددی—مانند جستجوی برداری در Azure AI Search، پایگاه‌های داده SQL یا APIهای سفارشی—را پیش از نهایی کردن پاسخ خود ادغام می‌کند. ویژگی متمایز سیستم عاملیک، توانایی مالکیت فرایند استدلال خود است. پیاده‌سازی‌های سنتی RAG به مسیرهای از پیش تعریف شده متکی هستند، اما سیستم عاملیک به‌طور خودکار توالی گام‌ها را بر اساس کیفیت اطلاعات یافت شده تعیین می‌کند.

## تعریف Agentic Retrieval-Augmented Generation (Agentic RAG)

Agentic Retrieval-Augmented Generation (Agentic RAG) پارادایم نوظهوری در توسعه هوش مصنوعی است که در آن LLMها نه تنها اطلاعات را از منابع داده خارجی استخراج می‌کنند، بلکه به‌صورت خودگردان گام‌های بعدی خود را برنامه‌ریزی می‌کنند. برخلاف الگوهای ایستا بازیابی-سپس-خواندن یا توالی‌های دقیق پرامپت‌نویسی شده، Agentic RAG شامل حلقه‌ای از فراخوانی‌های تکراری به LLM است که در میان آن‌ها فراخوانی ابزار یا تابع و خروجی‌های ساختاریافته قرار دارد. در هر مرحله، سیستم نتایج به‌دست آمده را ارزیابی می‌کند، تصمیم می‌گیرد که آیا باید پرسش‌ها را اصلاح کند، در صورت نیاز ابزارهای اضافی را فراخوانی می‌کند و این چرخه را تا رسیدن به راه‌حل رضایت‌بخش ادامه می‌دهد.

این سبک تکراری «سازنده-بازرس» برای بهبود دقت، مدیریت پرسش‌های نادرست به پایگاه‌های داده ساختاریافته (مانند NL2SQL) و تضمین نتایج متعادل و با کیفیت بالا طراحی شده است. به جای اتکا صرف به زنجیره‌های پرامپت پیچیده، سیستم به‌طور فعال مالک فرایند استدلال خود است. می‌تواند پرسش‌هایی که شکست می‌خورند را بازنویسی کند، روش‌های بازیابی متفاوتی را انتخاب کند و ابزارهای متعددی—مانند جستجوی برداری در Azure AI Search، پایگاه‌های داده SQL یا APIهای سفارشی—را پیش از نهایی کردن پاسخ خود ادغام کند. این امر نیاز به چارچوب‌های ارکستراسیون پیچیده را حذف می‌کند. در عوض، حلقه نسبتاً ساده «فراخوانی LLM → استفاده از ابزار → فراخوانی LLM → …» می‌تواند خروجی‌های پیچیده و مستدل ارائه دهد.

![Agentic RAG Core Loop](../../../translated_images/agentic-rag-core-loop.2224925a913fb3439f518bda61a40096ddf6aa432a11c9b5bba8d0d625e47b79.fa.png)

## مالکیت فرایند استدلال

ویژگی متمایزی که یک سیستم را «عامل» می‌کند، توانایی مالکیت فرایند استدلال آن است. پیاده‌سازی‌های سنتی RAG اغلب به انسان‌ها متکی هستند که مسیر مدل را از پیش تعریف کنند: زنجیره‌ای از تفکر که مشخص می‌کند چه چیزی و چه زمانی بازیابی شود.  
اما زمانی که یک سیستم واقعاً عامل است، به‌صورت داخلی تصمیم می‌گیرد چگونه به مسئله نزدیک شود. این فقط اجرای یک اسکریپت نیست؛ بلکه به‌طور خودگردان توالی گام‌ها را بر اساس کیفیت اطلاعات یافته شده تعیین می‌کند.  
برای مثال، اگر از آن خواسته شود استراتژی راه‌اندازی محصولی ایجاد کند، تنها به پرامپتی که کل جریان تحقیق و تصمیم‌گیری را مشخص می‌کند متکی نیست. در عوض، مدل عامل به‌طور مستقل تصمیم می‌گیرد که:

1. گزارش‌های روند بازار فعلی را با استفاده از Bing Web Grounding بازیابی کند  
2. داده‌های مرتبط با رقبا را با استفاده از Azure AI Search شناسایی کند  
3. شاخص‌های فروش داخلی تاریخی را با استفاده از Azure SQL Database همبسته کند  
4. یافته‌ها را به استراتژی منسجمی ترکیب کند که از طریق Azure OpenAI Service هماهنگ شده است  
5. استراتژی را برای شکاف‌ها یا ناسازگاری‌ها ارزیابی کند و در صورت نیاز دور دیگری از بازیابی را انجام دهد  

تمام این مراحل—اصلاح پرسش‌ها، انتخاب منابع، تکرار تا رضایت از پاسخ—توسط مدل تصمیم‌گیری می‌شود، نه توسط انسان از پیش اسکریپت شده.

## حلقه‌های تکراری، ادغام ابزار و حافظه

![Tool Integration Architecture](../../../translated_images/tool-integration.7b05a923e3278bf1fd2972faa228fb2ac725f166ed084362b031a24bffd26287.fa.png)

یک سیستم عاملیک بر الگوی تعامل حلقه‌ای تکیه دارد:

- **فراخوانی اولیه:** هدف کاربر (پرومپت کاربر) به LLM ارائه می‌شود.  
- **فراخوانی ابزار:** اگر مدل اطلاعات ناقص یا دستورالعمل‌های مبهم را شناسایی کند، ابزاری یا روش بازیابی‌ای را انتخاب می‌کند—مانند پرس‌وجوی پایگاه داده برداری (مثلاً جستجوی ترکیبی Azure AI Search روی داده‌های خصوصی) یا فراخوانی ساختاری SQL—برای جمع‌آوری زمینه بیشتر.  
- **ارزیابی و اصلاح:** پس از بررسی داده‌های بازگردانده شده، مدل تصمیم می‌گیرد آیا اطلاعات کافی است یا خیر. اگر کافی نبود، پرسش را اصلاح می‌کند، ابزار دیگری را امتحان می‌کند یا رویکرد خود را تغییر می‌دهد.  
- **تکرار تا رضایت:** این چرخه ادامه می‌یابد تا مدل تشخیص دهد که وضوح و شواهد کافی برای ارائه پاسخ نهایی و مستدل دارد.  
- **حافظه و حالت:** چون سیستم حالت و حافظه را در طول مراحل حفظ می‌کند، می‌تواند تلاش‌ها و نتایج قبلی را به خاطر بسپارد، از تکرار حلقه‌های بی‌مورد جلوگیری کند و تصمیمات آگاهانه‌تری اتخاذ نماید.  

با گذشت زمان، این باعث ایجاد درک در حال تکامل می‌شود که به مدل اجازه می‌دهد وظایف پیچیده چندمرحله‌ای را بدون نیاز به دخالت مداوم انسان یا تغییر پرامپت مدیریت کند.

## مدیریت خطاها و خوداصلاحی

خودمختاری Agentic RAG همچنین شامل مکانیزم‌های قوی خوداصلاحی است. وقتی سیستم به بن‌بست می‌رسد—مانند بازیابی اسناد نامربوط یا مواجهه با پرسش‌های نادرست—می‌تواند:

- **تکرار و بازپرسش:** به جای ارائه پاسخ‌های کم‌ارزش، مدل استراتژی‌های جستجوی جدیدی را امتحان می‌کند، پرسش‌های پایگاه داده را بازنویسی می‌کند یا به داده‌های جایگزین نگاه می‌کند.  
- **استفاده از ابزارهای تشخیصی:** سیستم ممکن است توابع اضافی را برای کمک به اشکال‌زدایی مراحل استدلال یا تأیید صحت داده‌های بازیابی شده فراخوانی کند. ابزارهایی مانند Azure AI Tracing برای فراهم کردن قابلیت مشاهده و نظارت قوی اهمیت دارند.  
- **اتکا به نظارت انسانی:** برای سناریوهای حساس یا مواردی که مکرراً شکست می‌خورند، مدل ممکن است عدم قطعیت را علامت‌گذاری کند و درخواست راهنمایی انسانی نماید. پس از ارائه بازخورد اصلاحی توسط انسان، مدل می‌تواند آن درس را در ادامه به کار گیرد.  

این رویکرد تکراری و پویا به مدل اجازه می‌دهد به طور مداوم بهبود یابد، تضمین می‌کند که فقط یک سیستم یک‌باره نیست بلکه سیستمی است که از اشتباهات خود در طول یک جلسه یاد می‌گیرد.

![Self Correction Mechanism](../../../translated_images/self-correction.3d42c31baf4a476bb89313cec58efb196b0e97959c04d7439cc23d27ef1242ac.fa.png)

## مرزهای عامل بودن

با وجود خودمختاری در انجام یک وظیفه، Agentic RAG معادل هوش مصنوعی عمومی نیست. قابلیت‌های «عامل» آن محدود به ابزارها، منابع داده و سیاست‌هایی است که توسط توسعه‌دهندگان انسانی فراهم شده‌اند. نمی‌تواند ابزارهای خود را اختراع کند یا از مرزهای حوزه تعیین شده خارج شود. بلکه در مدیریت پویا منابع موجود عملکرد برجسته‌ای دارد.  
تفاوت‌های کلیدی با اشکال پیشرفته‌تر هوش مصنوعی شامل موارد زیر است:

1. **خودمختاری حوزه‌محور:** سیستم‌های Agentic RAG بر دستیابی به اهداف تعریف شده توسط کاربر در حوزه‌ای شناخته شده تمرکز دارند و از استراتژی‌هایی مانند بازنویسی پرسش یا انتخاب ابزار برای بهبود نتایج استفاده می‌کنند.  
2. **وابستگی به زیرساخت:** قابلیت‌های سیستم به ابزارها و داده‌هایی وابسته است که توسط توسعه‌دهندگان یکپارچه شده‌اند و بدون دخالت انسان نمی‌تواند از این مرزها فراتر رود.  
3. **احترام به محدودیت‌ها:** دستورالعمل‌های اخلاقی، قوانین انطباق و سیاست‌های کسب‌وکار اهمیت بالایی دارند. آزادی عامل همواره تحت محدودیت‌های ایمنی و مکانیزم‌های نظارتی است (امیدواریم).

## موارد استفاده عملی و ارزش

Agentic RAG در موقعیت‌هایی که نیاز به اصلاح تکراری و دقت بالا دارند، برجسته است:

1. **محیط‌های اولویت‌دار بر صحت:** در بررسی‌های انطباق، تحلیل‌های مقرراتی یا تحقیقات حقوقی، مدل عامل می‌تواند مکرراً حقایق را تأیید کند، منابع متعدد را مشورت نماید و پرسش‌ها را بازنویسی کند تا پاسخ کاملاً بررسی شده‌ای ارائه دهد.  
2. **تعاملات پیچیده با پایگاه داده:** هنگام کار با داده‌های ساختاریافته که پرسش‌ها ممکن است اغلب شکست بخورند یا نیاز به تنظیم داشته باشند، سیستم می‌تواند پرسش‌ها را به‌طور خودگردان با استفاده از Azure SQL یا Microsoft Fabric OneLake اصلاح کند و اطمینان حاصل کند که بازیابی نهایی با هدف کاربر همسو است.  
3. **جریان‌های کاری گسترده:** جلسات طولانی‌تر ممکن است با ظهور اطلاعات جدید تکامل یابند. Agentic RAG می‌تواند به طور مداوم داده‌های جدید را وارد کند و استراتژی‌ها را با یادگیری بیشتر درباره فضای مسئله تغییر دهد.

## حاکمیت، شفافیت و اعتماد

با افزایش خودمختاری این سیستم‌ها در استدلال، حاکمیت و شفافیت اهمیت بالایی پیدا می‌کند:

- **استدلال قابل توضیح:** مدل می‌تواند ردپایی از پرسش‌هایی که انجام داده، منابعی که مشورت کرده و مراحل استدلالی که طی کرده برای رسیدن به نتیجه ارائه دهد. ابزارهایی مانند Azure AI Content Safety و Azure AI Tracing / GenAIOps به حفظ شفافیت و کاهش ریسک‌ها کمک می‌کنند.  
- **کنترل تعصب و بازیابی متعادل:** توسعه‌دهندگان می‌توانند استراتژی‌های بازیابی را تنظیم کنند تا منابع داده متعادل و نماینده در نظر گرفته شوند و به‌طور منظم خروجی‌ها را برای تشخیص تعصب یا الگوهای ناپایدار با استفاده از مدل‌های سفارشی برای سازمان‌های پیشرفته علوم داده مبتنی بر Azure Machine Learning بررسی کنند.  
- **نظارت انسانی و انطباق:** برای وظایف حساس، بازبینی انسانی همچنان ضروری است. Agentic RAG جایگزین قضاوت انسانی در تصمیمات حساس نمی‌شود—بلکه آن را با ارائه گزینه‌های کاملاً بررسی شده تقویت می‌کند.

داشتن ابزارهایی که سابقه روشنی از اقدامات ارائه می‌دهند ضروری است. بدون این‌ها، اشکال‌زدایی فرایند چندمرحله‌ای بسیار دشوار خواهد بود. نمونه زیر از Literal AI (شرکتی که پشت Chainlit است) برای یک اجرای Agent را مشاهده کنید:

![AgentRunExample](../../../translated_images/AgentRunExample.27e2df23ad898772d1b3e7a3e3cd4615378e10dfda87ae8f06b4748bf8eea97d.fa.png)

![AgentRunExample2](../../../translated_images/AgentRunExample2.c0e8c78b1f2540a641515e60035abcc6a9c5e3688bae143eb6c559dd37cdee9f.fa.png)

## نتیجه‌گیری

Agentic RAG نمایانگر تکامل طبیعی در نحوه مدیریت سیستم‌های هوش مصنوعی وظایف پیچیده و داده‌محور است. با اتخاذ الگوی تعامل حلقه‌ای، انتخاب خودگردان ابزارها و اصلاح پرسش‌ها تا رسیدن به نتیجه‌ای با کیفیت بالا، سیستم فراتر از پیروی ایستا از پرامپت‌ها به یک تصمیم‌گیرنده تطبیقی و آگاه به زمینه تبدیل می‌شود. اگرچه هنوز محدود به زیرساخت‌ها و دستورالعمل‌های اخلاقی تعریف شده توسط انسان است، این قابلیت‌های عامل امکان تعاملات هوشمندانه‌تر، پویاتر و در نهایت مفیدتر هوش مصنوعی را برای سازمان‌ها و کاربران نهایی فراهم می‌کند.

## منابع اضافی

- <a href="https://learn.microsoft.com/training/modules/use-own-data-azure-openai" target="_blank">پیاده‌سازی Retrieval Augmented Generation (RAG) با Azure OpenAI Service: یادگیری نحوه استفاده از داده‌های خود با سرویس Azure OpenAI. این ماژول Microsoft Learn راهنمای جامعی برای پیاده‌سازی RAG ارائه می‌دهد</a>  
- <a href="https://learn.microsoft.com/azure/ai-studio/concepts/evaluation-approach-gen-ai" target="_blank">ارزیابی برنامه‌های هوش مصنوعی مولد با Azure AI Foundry: این مقاله به ارزی

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما در تلاش برای دقت هستیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است حاوی خطاها یا نواقصی باشند. سند اصلی به زبان بومی خود باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حیاتی، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما مسئول هیچ گونه سوء تفاهم یا تفسیر نادرستی که از استفاده این ترجمه ناشی شود، نیستیم.